<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  
    
      
    

    
  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=PT Serif:300,300italic,400,400italic,700,700italic|Abril Fatface:300,300italic,400,400italic,700,700italic|PT Serif:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="machine learning,algorithm,loss function,logistic regression,Newton's method," />










<meta name="description" content="Insight of logistic regression and Newton&#39;s method">
<meta property="og:type" content="article">
<meta property="og:title" content="Logistic Regression Updated with Newton&#39;s Method">
<meta property="og:url" content="http://yoursite.com/2020/04/20/logsiticRegression/index.html">
<meta property="og:site_name" content="TERRY&#39;S BLOG">
<meta property="og:description" content="Insight of logistic regression and Newton&#39;s method">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/e/e0/NewtonIteration_Ani.gif">
<meta property="og:image" content="https://openstax.org/resources/03a495b2b2b3d4dfa2b027fccdae44d1aba527a1">
<meta property="article:published_time" content="2020-04-20T16:44:06.000Z">
<meta property="article:modified_time" content="2020-04-21T05:40:34.715Z">
<meta property="article:author" content="Yiheng &#39;Terry&#39; Li">
<meta property="article:tag" content="machine learning">
<meta property="article:tag" content="algorithm">
<meta property="article:tag" content="loss function">
<meta property="article:tag" content="logistic regression">
<meta property="article:tag" content="Newton&#39;s method">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2020/04/20/logsiticRegression/"/>





  <title>Logistic Regression Updated with Newton's Method | TERRY'S BLOG</title>
  








<meta name="generator" content="Hexo 4.2.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">TERRY'S BLOG</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Footprints, Thoughts and Accumulation</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/20/logsiticRegression/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yiheng 'Terry' Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar_img.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TERRY'S BLOG">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Logistic Regression Updated with Newton's Method</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-04-20T09:44:06-07:00">
                2020-04-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NOTE/" itemprop="url" rel="index">
                    <span itemprop="name">NOTE</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/04/20/logsiticRegression/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2020/04/20/logsiticRegression/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          
              <div class="post-description">
                  Insight of logistic regression and Newton's method
              </div>
          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>Logistic regression is a very important binary classification algorithm, in this article, some essential details inside the algorithm will be discussed. Plain language will be used to discuss the most detail aspects so that beginners of machine learning can easily get the idea.</p>
<h2 id="Assumptions-of-Logistic-Regression"><a href="#Assumptions-of-Logistic-Regression" class="headerlink" title="Assumptions of Logistic Regression"></a>Assumptions of Logistic Regression</h2><p>Logistic regression does not require as many assumptions as linear regression. There are a few that are interested and we will shortly discussed about.</p>
<ol>
<li>The error terms are independent to each other.<ul>
<li>In the experiment design, each sample should be “equivalent” to each other, no paired/match samples or before/after experiment samples.</li>
</ul>
</li>
<li>There is no high correlations between the features (multicollinearity).<ul>
<li>The model might not converge in this case by MLE estimate</li>
</ul>
</li>
<li>The log odds has linear relationship with the independent variables.<ul>
<li>While we underlyingly assuming this, it would not hold true in most cases. There is no extra step to test this assumption. And if it fails, logistic regression just won’t work. So in practice, we try logistic regression to “test” this assumption.</li>
</ul>
</li>
<li>The dependent variable follows a Bernoulli distribution.<ul>
<li>By this we assume that $Y \sim \text{Bernoulli}(\phi)$, and automatically independent to each other.</li>
</ul>
</li>
</ol>
<h2 id="Insight-of-Logistic-Regression"><a href="#Insight-of-Logistic-Regression" class="headerlink" title="Insight of Logistic Regression"></a>Insight of Logistic Regression</h2><h4 id="Constructing-the-Model"><a href="#Constructing-the-Model" class="headerlink" title="Constructing the Model"></a>Constructing the Model</h4><p>In practice, assuming we have our features $X \in \mathbb{R}^{n \times d}$, and we want to predict a binary response $Y<em>i \in {0,1}$ for each sample of features. What we do is creating model that outputs $p(y=1) = \phi = h</em>\theta(x)$. According to the assumption, the <strong>log odds</strong> </p>
<script type="math/tex; mode=display">
\text{logit}(\phi) = \log(\frac{\phi}{1-\phi})</script><p>has a linear relationship with the features. We use a vector $\theta \in \mathbb{R}^{d}$ to denote this linear relationship:</p>
<script type="math/tex; mode=display">
\log(\frac{\phi}{1-\phi}) = \theta^Tx</script><p>So, we get the model’s predictions will be:</p>
<script type="math/tex; mode=display">
h_\theta(x)= g(\theta^Tx) = \frac{1}{1+e^{-\theta^Tx}}</script><p>where $g(z)$ is called <strong><a href="https://en.wikipedia.org/wiki/Sigmoid_function" target="_blank" rel="noopener">sigmoid function</a></strong>, which is an important function in machine learning.</p>
<script type="math/tex; mode=display">
g(z) = \frac{1}{1+e^{z}}</script><p><img src="https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg" alt="sigmoid" title="Shape of Sigmoid Function"></p>
<p>The model’s goal is trying to learn the parameters $\theta$.</p>
<h2 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h2><h4 id="Define-Loss"><a href="#Define-Loss" class="headerlink" title="Define Loss"></a>Define Loss</h4><p>To find the “best” $\theta$, we should first define what is “better”. The <strong>loss function</strong> of a model denotes how well the model fits the data (the better the model, the fewer the loss). Thus the process of finding the best $\theta$ is concretized to minimizing the loss function of a model. we define the loss function of logistic regression as follows:</p>
<script type="math/tex; mode=display">
L(y, \hat y) = -(y^{(i)}\log(\hat y^{(i)}) + (1-y^{(i)})\log(1-\hat y^{(i)}))</script><p>This function is binary form of <a href="https://en.wikipedia.org/wiki/Cross_entropy" target="_blank" rel="noopener"><strong>cross entropy loss</strong></a>, which is widely used in classification models.</p>
<h4 id="Intuition-of-Loss-function"><a href="#Intuition-of-Loss-function" class="headerlink" title="Intuition of Loss function"></a>Intuition of Loss function</h4><p>Here provides an intuition of why this loss function is chosen. As we mentioned in assumptions we made, $y \sim \text{Bernoulli}(\phi)$. So the pdf of $y$ can be written as</p>
<script type="math/tex; mode=display">
p(y|x) = \Phi^{y}(1 - \Phi)^{(1-y)}</script><p>In our model, $\phi$ is estimated by $h_\theta(x)$. To make this probability model to resemble $y$ the most, it is a natural thing to maximize it’s likelihood. The following two step resembles the process of calculating MLE of $\phi$. We have the likelihood is:</p>
<script type="math/tex; mode=display">
L(y^{(i)}|x^{(i)};\theta) = h_\theta(x)^{y}(1-h_\theta(x))^{(1-y)}</script><p>The log-likelihood is:</p>
<script type="math/tex; mode=display">
l(y^{(i)}|x^{(i)};\theta) = y^{(i)}\log(h_\theta(x)) + (1 - y^{(i)})\log(1-h_\theta(x))</script><p>Noticing that log-likelihood is negative of loss function of the model. <u>Minimizing the loss function is equivalent to maximizing the likelihood of the parameter in Bernoulli distribution of $y$.</u> </p>
<h2 id="Fit-the-Model"><a href="#Fit-the-Model" class="headerlink" title="Fit the Model"></a>Fit the Model</h2><p>With the assumptions about the distribution of $y$ and the relationship between the response and the features, we constructed the model and defined the parameters that requires optimizing. We defined that the better the parameters, the larger the likelihood of $y$ comes from the distribution that we assumed. Now, in order to optimize $\theta$, instead of trying out every single combination of possible values of $\theta$, we need a parameter searching technique. </p>
<h4 id="Newton’s-Method"><a href="#Newton’s-Method" class="headerlink" title="Newton’s Method"></a>Newton’s Method</h4><p>Apart from gradient descent, we have a another technique that sometimes (this “sometimes” includes logistic regression) run much faster, called Newton’s method. Which is a method used for recursively looking for root of a function. Here is the idea of Newton’s method:</p>
<ol>
<li>Start with an initial guess which is reasonably close to the true root $x_0$;</li>
<li>Then to approximate the function using the first derivative of this point $f’(x_0)$, and draw a tangent line;</li>
<li>And finally to compute the x-intercept of this tangent line. This x-intercept will typically be a better approximation to the original function’s root than the first guess;</li>
<li>Iterated.</li>
</ol>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/e/e0/NewtonIteration_Ani.gif" alt="newton’s method gif" title="GIF Illustration of Newton's Method" style="zoom:80%;" /></p>
<p><img src="https://openstax.org/resources/03a495b2b2b3d4dfa2b027fccdae44d1aba527a1" alt="newtons method png" title="Newton's Method: How to Get Next Guesses of Root of a Function" style="zoom: 80%;" /></p>
<p>The update rule for Newton’s method is as follows (not hard to get):</p>
<script type="math/tex; mode=display">
x_{n+1} = x_{n} - \frac{f(x_n)}{f'(x_n)}</script><p>For our problem, we want to maximize the likelihood function, if this function is convex (in fact it is), then our mission is equivalent to <strong>find the root of the first derivative of log-likelihood</strong>. Using Newton’s method to do this, our update rule is:</p>
<script type="math/tex; mode=display">
\theta := \theta - \frac{l'(\theta)}{l''(\theta)}</script><p>where, as $\theta$ is a vector instead of a real value in most practical cases. Using the linear algebra form of first derivatives looks like this:</p>
<script type="math/tex; mode=display">
\nabla_\theta l = 
\begin{bmatrix}
    \frac{\partial}{\partial\theta_1}l(\theta) \\\\
    \frac{\partial}{\partial\theta_2}l(\theta) \\\\
    \vdots \\\\
    \frac{\partial}{\partial\theta_d}l(\theta) \\\\
\end{bmatrix}</script><p>And second derivative is called Hessian matrix $\textbf{H} = \nabla^2 l(\theta) \in \mathbb{R}^{d \times d}$.</p>
<script type="math/tex; mode=display">
\textbf{H}_{ij} = \frac{\partial^2l(\theta)}{\partial\theta_i\partial\theta_j}</script><h4 id="Trade-off-between-Newton’s-Method-and-Gradient-Descent"><a href="#Trade-off-between-Newton’s-Method-and-Gradient-Descent" class="headerlink" title="Trade-off between Newton’s Method and Gradient Descent"></a>Trade-off between Newton’s Method and Gradient Descent</h4><p>Though Newton’s method typically takes much shorter iterations of update to converge compared to gradient descent. It requires the calculation of first and the secondary derivative of the loss function, while gradient descent only requires the first derivative. So in each iteration, the calculation cost for Newton’s method is higher, especially when we cannot trace back the function and explicitly calculate the second derivative. Thus though we can implement Newton’s method here and achieve a faster convergence. This case might not be true for most of other algorithms, typically the more complicated ones. That is why gradient descent is still the most handy option for many other machine learning applications.</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol>
<li><a href="https://en.wikipedia.org/wiki/Newton%27s_method" target="_blank" rel="noopener">WIKIPEDIA</a></li>
<li><p><a href="https://openstax.org/books/calculus-volume-1/pages/4-9-newtons-method" target="_blank" rel="noopener">OPENSTAX</a></p>
</li>
<li><p><a href="http://cs229.stanford.edu/notes/cs229-notes1.pdf" target="_blank" rel="noopener">STANFORD CS229</a></p>
</li>
</ol>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/machine-learning/" rel="tag"># machine learning</a>
          
            <a href="/tags/algorithm/" rel="tag"># algorithm</a>
          
            <a href="/tags/loss-function/" rel="tag"># loss function</a>
          
            <a href="/tags/logistic-regression/" rel="tag"># logistic regression</a>
          
            <a href="/tags/Newton-s-method/" rel="tag"># Newton's method</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/04/15/pickle/" rel="next" title="Store Almost Any Objects of Python in Files">
                <i class="fa fa-chevron-left"></i> Store Almost Any Objects of Python in Files
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/04/24/generative-models/" rel="prev" title="Generative Models -- Gaussian Discriminant Analysis">
                Generative Models -- Gaussian Discriminant Analysis <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar_img.png"
                alt="Yiheng 'Terry' Li" />
            
              <p class="site-author-name" itemprop="name">Yiheng 'Terry' Li</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">19</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/terryli710" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="li.terry710@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.instagram.com/_unone__/" target="_blank" title="Instagram">
                      
                        <i class="fa fa-fw fa-instagram"></i>Instagram</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Assumptions-of-Logistic-Regression"><span class="nav-number">1.</span> <span class="nav-text">Assumptions of Logistic Regression</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Insight-of-Logistic-Regression"><span class="nav-number">2.</span> <span class="nav-text">Insight of Logistic Regression</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Constructing-the-Model"><span class="nav-number">2.0.1.</span> <span class="nav-text">Constructing the Model</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Loss-function"><span class="nav-number">3.</span> <span class="nav-text">Loss function</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Define-Loss"><span class="nav-number">3.0.1.</span> <span class="nav-text">Define Loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Intuition-of-Loss-function"><span class="nav-number">3.0.2.</span> <span class="nav-text">Intuition of Loss function</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Fit-the-Model"><span class="nav-number">4.</span> <span class="nav-text">Fit the Model</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Newton’s-Method"><span class="nav-number">4.0.1.</span> <span class="nav-text">Newton’s Method</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Trade-off-between-Newton’s-Method-and-Gradient-Descent"><span class="nav-number">4.0.2.</span> <span class="nav-text">Trade-off between Newton’s Method and Gradient Descent</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References"><span class="nav-number">5.</span> <span class="nav-text">References</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yiheng 'Terry' Li</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: 'nA0z6t6V440lRv0XQbFpR129-MdYXbMMI',
        appKey: '4YKR5znQYtCiWJjA47hoohhE',
		lang: 'en',
        placeholder: 'Just go go',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  





  

  
  <script src="https://www.gstatic.com/firebasejs/4.6.0/firebase.js"></script>
  <script src="https://www.gstatic.com/firebasejs/4.6.0/firebase-firestore.js"></script>
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/bluebird/3.5.1/bluebird.core.min.js"></script>
  
  <script>
    (function () {

      firebase.initializeApp({
        apiKey: 'AIzaSyBlUlNsFB6908AmwkUrSvvzG3g7D64rTiQ',
        projectId: 'count-d29fd'
      })

      function getCount(doc, increaseCount) {
        //increaseCount will be false when not in article page

        return doc.get().then(function (d) {
          var count
          if (!d.exists) { //has no data, initialize count
            if (increaseCount) {
              doc.set({
                count: 1
              })
              count = 1
            }
            else {
              count = 0
            }
          }
          else { //has data
            count = d.data().count
            if (increaseCount) {
              if (!(window.localStorage && window.localStorage.getItem(title))) { //if first view this article
                doc.set({ //increase count
                  count: count + 1
                })
                count++
              }
            }
          }
          if (window.localStorage && increaseCount) { //mark as visited
            localStorage.setItem(title, true)
          }

          return count
        })
      }

      function appendCountTo(el) {
        return function (count) {
          $(el).append(
            $('<span>').addClass('post-visitors-count').append(
              $('<span>').addClass('post-meta-divider').text('|')
            ).append(
              $('<span>').addClass('post-meta-item-icon').append(
                $('<i>').addClass('fa fa-users')
              )
              ).append($('<span>').text('Visitors ' + count))
          )
        }
      }

      var db = firebase.firestore()
      var articles = db.collection('articles')

      //https://hexo.io/zh-tw/docs/variables.html
      var isPost = 'Logistic Regression Updated with Newton's Method'.length > 0
      var isArchive = '' === 'true'
      var isCategory = ''.length > 0
      var isTag = ''.length > 0

      if (isPost) { //is article page
        var title = 'Logistic Regression Updated with Newton's Method'
        var doc = articles.doc(title)

        getCount(doc, true).then(appendCountTo($('.post-meta')))
      }
      else if (!isArchive && !isCategory && !isTag) { //is index page
        var titles = [] //array to titles

        var postsstr = '' //if you have a better way to get titles of posts, please change it
        eval(postsstr)

        var promises = titles.map(function (title) {
          return articles.doc(title)
        }).map(function (doc) {
          return getCount(doc)
        })
        Promise.all(promises).then(function (counts) {
          var metas = $('.post-meta')
          counts.forEach(function (val, idx) {
            appendCountTo(metas[idx])(val)
          })
        })
      }
    })()
  </script>


  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  


  

  

</body>
</html>
